{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10509960,"sourceType":"datasetVersion","datasetId":6506166},{"sourceId":10519151,"sourceType":"datasetVersion","datasetId":6510990},{"sourceId":10527132,"sourceType":"datasetVersion","datasetId":6515133}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\n\nsys.path.insert(0, '/kaggle/input/rag-utils')\n\nfrom subprocess_runner import run_command\nfrom file_operations import parse_file, save_embeddings, load_embeddings\nfrom embedding_operations import get_chunks_embeddings, get_prompt_embedding, find_most_similar, query_model_with_context\n\nos.chdir('/kaggle/working/')\nprint(os.getcwd())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T14:44:43.283467Z","iopub.execute_input":"2025-01-20T14:44:43.283749Z","iopub.status.idle":"2025-01-20T14:44:43.288523Z","shell.execute_reply.started":"2025-01-20T14:44:43.283728Z","shell.execute_reply":"2025-01-20T14:44:43.287840Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"run_command(\"curl -fsSL https://ollama.com/install.sh | sh\")\nos.system(\"/usr/local/bin/ollama serve &\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T14:27:04.052323Z","iopub.execute_input":"2025-01-20T14:27:04.052613Z","iopub.status.idle":"2025-01-20T14:27:51.267994Z","shell.execute_reply.started":"2025-01-20T14:27:04.052590Z","shell.execute_reply":"2025-01-20T14:27:51.266837Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n  self.stdout = io.open(c2pread, 'rb', bufsize)\n/usr/lib/python3.10/subprocess.py:966: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n  self.stderr = io.open(errread, 'rb', bufsize)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"run_command(\"ollama pull mistral\")\nrun_command(\"curl http://127.0.0.1:11434/api/chat -d '{\\\"model\\\": \\\"mistral\\\", \\\"stream\\\": false, \\\"messages\\\": [{ \\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Write a sentence as J. D. Salinger would write it\\\" }]}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T14:27:51.269150Z","iopub.execute_input":"2025-01-20T14:27:51.269379Z","iopub.status.idle":"2025-01-20T14:28:33.566765Z","shell.execute_reply.started":"2025-01-20T14:27:51.269360Z","shell.execute_reply":"2025-01-20T14:28:33.566023Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'{\"model\":\"mistral\",\"created_at\":\"2025-01-20T14:28:33.561080829Z\",\"message\":{\"role\":\"assistant\",\"content\":\" \\\\\"On a whimsy of a Tuesday morning, as the sun danced across the windowpane, Holden Caulfield found himself musing over a seemingly ordinary moment, yet discovering in it the extraordinary revelation of his own existential confusion.\\\\\"\"},\"done_reason\":\"stop\",\"done\":true,\"total_duration\":3627057020,\"load_duration\":2245170239,\"prompt_eval_count\":18,\"prompt_eval_duration\":351000000,\"eval_count\":54,\"eval_duration\":1029000000}'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"filename = \"../input/peter-pan/peter_pan.txt.txt\"\nparagraphs = parse_file(filename)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T14:30:18.061126Z","iopub.execute_input":"2025-01-20T14:30:18.061442Z","iopub.status.idle":"2025-01-20T14:30:18.071006Z","shell.execute_reply.started":"2025-01-20T14:30:18.061419Z","shell.execute_reply":"2025-01-20T14:30:18.070028Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"embeddings = get_chunks_embeddings(filename, \"mistral\", paragraphs)\nprint(\"Embeddings generated successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T14:30:47.831656Z","iopub.execute_input":"2025-01-20T14:30:47.831999Z","iopub.status.idle":"2025-01-20T14:40:51.872136Z","shell.execute_reply.started":"2025-01-20T14:30:47.831970Z","shell.execute_reply":"2025-01-20T14:40:51.871256Z"}},"outputs":[{"name":"stderr","text":"Processing chunks: 100%|██████████| 1736/1736 [09:55<00:00,  2.92chunk/s]\n","output_type":"stream"},{"name":"stdout","text":"Embeddings generated successfully!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"SYSTEM_PROMPT = \"\"\"You are a helpful reading assistant who answers questions \n    based on snippets of text provided in context. Answer only using the context provided, \n    being as concise as possible. If you're unsure, just say that you don't know.\n    Context:\n\"\"\"\n\nprompt = \"Who's the story primary villain?\"\n\nprompt_embedding = get_prompt_embedding(prompt, modelname=\"mistral\")\nmost_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T14:44:27.272186Z","iopub.execute_input":"2025-01-20T14:44:27.272486Z","iopub.status.idle":"2025-01-20T14:44:29.119919Z","shell.execute_reply.started":"2025-01-20T14:44:27.272464Z","shell.execute_reply":"2025-01-20T14:44:29.119169Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"response = query_model_with_context(\n    modelname=\"mistral\",\n    system_prompt=SYSTEM_PROMPT,\n    prompt=prompt,\n    most_similar_chunks=most_similar_chunks,\n    paragraphs=paragraphs,\n)\n\nif response is not None:\n    print(\"Model response:\")\n    print(response['content'])\nelse:\n    print(\"Failed to get a response from the model.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T14:44:46.671426Z","iopub.execute_input":"2025-01-20T14:44:46.671731Z","iopub.status.idle":"2025-01-20T14:44:47.814793Z","shell.execute_reply.started":"2025-01-20T14:44:46.671704Z","shell.execute_reply":"2025-01-20T14:44:47.814134Z"}},"outputs":[{"name":"stdout","text":"Model response:\n The context does not provide enough information to determine who the primary villain in the story is.\n","output_type":"stream"}],"execution_count":18}]}